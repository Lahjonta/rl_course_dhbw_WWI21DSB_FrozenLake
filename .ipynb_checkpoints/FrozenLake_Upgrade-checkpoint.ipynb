{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb43739",
   "metadata": {},
   "source": [
    "# Frozen Lake with Q-Learning\n",
    "\n",
    "#### Code Source: for basic initialization adapted from https://github.com/Viddesh1/RL/blob/main/Mini_Project.ipynb\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries for standard Frozen Lake\n",
    "import numpy as np # For fast numeric / linear algebra computation.\n",
    "import time        # For controling time of execution.  \n",
    "import pickle      # For storing updated Q-table.\n",
    "import gym         # For working with open AI frozen lake v1 environment and utilities.\n",
    "import matplotlib.pyplot as plt # For plotting rewards over iterations.\n",
    "\n",
    "\n",
    "# Importing the necessary libraries for Frozen Lake 2.0\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map, FrozenLakeEnv # For taking basics from standard Frozen lake to adapt to our use case\n",
    "from contextlib import closing  # Ensures proper cleanup of resources\n",
    "from io import StringIO  # In-memory text stream for ANSI rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1bdf1",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters for both standard and 2.0\n",
    "total_episodes = 10000 # Total number of iterations or episodes of training.\n",
    "\n",
    "# A higher value of epsilon encourages more exploration, while a lower value of epsilon favors exploitation.\n",
    "initial_epsilon = 1.0   # Initial exploration rate\n",
    "min_epsilon = 0.1       # Minimum exploration rate (increased to ensure exploration)\n",
    "epsilon_decay = 0.999 # Slow decay to allow exploration\n",
    "\n",
    "max_steps = 100 # Maximum number of steps that agent can take in environment\n",
    "\n",
    "lr_rate = 0.81 # Learning Rate of convergence to global minimum\n",
    "\n",
    "# A high discount factor means that future rewards are highly valued, while a \n",
    "# low discount factor means that immediate rewards are given greater weight\n",
    "gamma = 0.96 # Discount Factor, Positive real number (0 < gamma < 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24b46e",
   "metadata": {},
   "source": [
    "## Frozen Lake Standard Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a81553",
   "metadata": {},
   "source": [
    "### Create Environment from OpenGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating environment using gym package.\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"ansi\", is_slippery=False) # ansi to render because JN has some issues with rendering #4x4 Lake \n",
    "# if wanted -> set: is_slippery=True for more complex example, or =False for guaranteed solution\n",
    "\n",
    "print(\"Number of observation states: \", env.observation_space.n)\n",
    "print(\"Number of action space : \", env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ccd87",
   "metadata": {},
   "source": [
    "### Initialize Q-Table for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Q-table with zeros for 2-D array of (observation_space, action_space).\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b5f6",
   "metadata": {},
   "source": [
    "### Define Action Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, epsilon):\n",
    "    \"\"\" \n",
    "    The choose_action() function used a Epsilon-Greedy policy for Exploration and Exploitation.\n",
    "    \n",
    "    Exploration is done when uniform random number from 0 to 1 is less than epsilon value.\n",
    "    Else, Maximum value of the state and action pair is taken which is Exploitation.\n",
    "\n",
    "    Args:\n",
    "        state (int): Gets the current state as parameter/\n",
    "\n",
    "    Returns:\n",
    "        int: Returns action to be taken in that state\n",
    "    \"\"\"\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Explore: choose a random action\n",
    "    else:\n",
    "        return np.argmax(Q[state, :])     # Exploit: choose the action with the highest value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02cada1",
   "metadata": {},
   "source": [
    "### Define Learning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a70159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(state, state2, reward, action):\n",
    "    \"\"\" \n",
    "    Updates the Q-table.\n",
    "    Agent learn to find a optimal policy by using bellman optimality equation.\n",
    "\n",
    "    Args:\n",
    "        state (int): Current state\n",
    "        state2 (int): Future state\n",
    "        reward (int): Reward if rached to goal state\n",
    "        action (int): action states\n",
    "    \"\"\"\n",
    "    predict = Q[state, action]\n",
    "    target = reward + gamma * np.max(Q[state2, :])\n",
    "    Q[state, action] = Q[state, action] + lr_rate * (target - predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595fc603",
   "metadata": {},
   "source": [
    "### Look at a Try Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment to initial state\n",
    "state, _ = env.reset()\n",
    "\n",
    "# Render the initial state\n",
    "print(env.render())\n",
    "\n",
    "# Take a few random steps to see the environment in action\n",
    "for _ in range(5):\n",
    "    action = env.action_space.sample()  # Choose a random action\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    print(env.render())\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4d153",
   "metadata": {},
   "source": [
    "#### Frozen Lake Environment and Meaning of Fields"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b9aa9c2",
   "metadata": {},
   "source": [
    "S F F F       (S: starting point, safe)\n",
    "F H F H       (F: frozen surface, safe)\n",
    "F F F H       (H: hole, stuck forever)\n",
    "H F F G       (G: goal, safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9d6a5",
   "metadata": {},
   "source": [
    "### Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aa7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "epsilon = initial_epsilon\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(max_steps):\n",
    "        action = choose_action(state, epsilon)\n",
    "        state2, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        learn(state, state2, reward, action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = state2\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # Decay epsilon\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "    \n",
    "    rewards.append(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a88d7",
   "metadata": {},
   "source": [
    "### Plot Reward Function Over Iterations of Training\n",
    "\n",
    "#### Only Reward is Given for Reaching Goal (+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6de97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check learning progress via average rewards\n",
    "def plot_metrics(episodes, rewards):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episodes, rewards, label='Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Reward per Episode')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average rewards over 100 episodes\n",
    "avg_rewards = []\n",
    "for i in range(0, len(rewards), 100):\n",
    "    avg_rewards.append(np.mean(rewards[i:i+100]))\n",
    "\n",
    "### Plot Rewards over Iterations to see progress\n",
    "plt.plot(avg_rewards)\n",
    "plt.xlabel('Episode Number x100')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Total Average Reward per 100 Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2334c56",
   "metadata": {},
   "source": [
    "### Look at a Walkthrough after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672027ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the environment after training is complete\n",
    "state, _ = env.reset()  # Reset the environment for the final render\n",
    "t = 0\n",
    "\n",
    "print(\"Final try after training:\")\n",
    "while t < max_steps:\n",
    "    print(env.render())  # Render the environment after training\n",
    "\n",
    "    action = np.argmax(Q[state, :])  # Take the best action based on the learned Q-table\n",
    "    state, reward, done, truncated, info = env.step(action)  # Take action and observe outcome\n",
    "    t += 1\n",
    "\n",
    "    if done:  # End episode if goal is reached\n",
    "        break\n",
    "\n",
    "    time.sleep(0.1)  # Slow down the process for better observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc635f6f",
   "metadata": {},
   "source": [
    "### Look at and Save Our Trained Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bbd233",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the Q-table in pickle file for easy loading when needed.\n",
    "with open(\"frozenLake_qTable.pkl\", 'wb') as f:\n",
    "    pickle.dump(Q, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49651b",
   "metadata": {},
   "source": [
    "## Frozen Lake 2.0\n",
    "\n",
    "### Create a Custom Frozen Lake Environment\n",
    "\n",
    "#### Code source: own creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0cdc0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFrozenLakeEnv(FrozenLakeEnv):\n",
    "    def __init__(self, desc=None, map_name=\"4x4\", is_slippery=False):\n",
    "        if desc is not None:\n",
    "            desc = np.array([list(row) for row in desc], dtype='c')\n",
    "        super().__init__(desc=desc, map_name=map_name, is_slippery=is_slippery)\n",
    "        self.booster_tile = 'B'\n",
    "        self.goal_tile = 'G'\n",
    "        self.hole_tile = 'H'\n",
    "        self.enemy_tile = 'E'\n",
    "        self.frozen_tile = 'F'\n",
    "        self.weapon_tile = 'W'\n",
    "        self.boost_active = False\n",
    "        self.has_weapon = False\n",
    "        self.agent_pos = (0, 0)  # Agent starts in the top left corner\n",
    "        self.enemy_pos = (3, 7)  # Initialize enemy position\n",
    "        self.weapon_pos = (2, 1) # Position of the weapon\n",
    "        self.goal_pos = (7, 7)\n",
    "        self.desc_original = self.desc.copy()  # Store the original description map\n",
    "        self.original_tile_enemy = 'F' # Replaces Enemy's tile after it starts moving\n",
    "        self.enemy_active = True # Deactivated after enemy is defeated\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.boost_active = False\n",
    "        state = super().reset(**kwargs)\n",
    "        self.agent_pos = (0, 0)  # Agent starts in the top left corner\n",
    "        self.enemy_pos = (3, 7)  # Initialize enemy position\n",
    "        self.weapon_pos = (2, 1) # Initialize weapon position\n",
    "        self.desc = self.desc_original.copy()  # Reset the description map\n",
    "        self.desc[self.enemy_pos[0]][self.enemy_pos[1]] = self.enemy_tile.encode()  # Place enemy on the map again\n",
    "        self.desc[self.weapon_pos[0]][self.weapon_pos[1]] = self.weapon_tile.encode()  # Place weapon on the map again\n",
    "        self.has_weapon = False # Reset weapon status\n",
    "        self.enemy_active = True  # Reset enemy status\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        truncated = False  # Assume no truncation\n",
    "\n",
    "        if self.boost_active:\n",
    "            self.boost_active = False  # Reset the boost after using it\n",
    "            next_state = self.skip_step(self.s, action)\n",
    "            if next_state is not None:\n",
    "                self.s = next_state\n",
    "                row, col = divmod(self.s, self.ncol)\n",
    "                self.agent_pos = (row, col)\n",
    "                if self.desc[row][col] == self.booster_tile.encode():  # Check if on booster tile\n",
    "                    self.boost_active = True  # Activate boost again if landing on another booster\n",
    "                if self.desc[row][col] == self.weapon_tile.encode():  # Agent collects weapon\n",
    "                    self.has_weapon = True\n",
    "                    self.desc[row][col] = self.frozen_tile.encode()  # Change weapon tile to normal frozen tile once weapon is collected\n",
    "                if self.desc[row][col] == self.enemy_tile.encode():\n",
    "                    if self.has_weapon:\n",
    "                        self.remove_enemy()  # Remove enemy if agent has weapon when meeting\n",
    "                    else:\n",
    "                        done = True  # Game Over if agent meets enemy and doesn't have a weapon\n",
    "                # Move the enemy and update the map\n",
    "                reward = self.get_reward(row, col)\n",
    "                done = self.desc[row][col] in [self.goal_tile.encode(), self.hole_tile.encode()]  # Game Over if goal reached or when agent fell into a hole\n",
    "                self.move_enemy()\n",
    "                return self.s, reward, done, truncated, {}\n",
    "            else:\n",
    "                # If the skip step results in an invalid state, perform a normal step\n",
    "                state, reward, done, truncated, info = super().step(action)\n",
    "                self.agent_pos = divmod(state, self.ncol)\n",
    "        else:\n",
    "            state, reward, done, truncated, info = super().step(action)\n",
    "            self.agent_pos = divmod(state, self.ncol)\n",
    "            row, col = self.agent_pos\n",
    "            if self.desc[row][col] == self.weapon_tile.encode():  # Agent collects weapon\n",
    "                self.has_weapon = True\n",
    "                self.desc[row][col] = self.frozen_tile.encode()  # Change weapon tile to normal frozen tile once weapon is collected\n",
    "        if self.desc[row][col] == self.booster_tile.encode():  # Check if on booster tile\n",
    "            self.boost_active = True  # Activate boost\n",
    "        if self.enemy_active and self.desc[row][col] == self.enemy_tile.encode():\n",
    "            if self.has_weapon:\n",
    "                self.remove_enemy()  # Remove enemy if agent has weapon when meeting\n",
    "            else:\n",
    "                done = True  # Game Over if agent meets enemy and doesn't have a weapon\n",
    "        # Collect rewards and Move the enemy and update the map\n",
    "        done = self.desc[row][col] in [self.goal_tile.encode(), self.hole_tile.encode()]  # Game Over if goal reached or when agent fell into a hole\n",
    "        reward = self.get_reward(row, col)\n",
    "        self.move_enemy()\n",
    "\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "    def skip_step(self, state, action):\n",
    "        \"\"\"\n",
    "        If agent lands on a boost field, the next step will be 2 tiles long instead of one\n",
    "        \"\"\"\n",
    "        row, col = divmod(state, self.ncol)\n",
    "        if action == 0:  # Left\n",
    "            col = max(0, col - 2)\n",
    "        elif action == 1:  # Down\n",
    "            row = min(self.nrow - 1, row + 2)\n",
    "        elif action == 2:  # Right\n",
    "            col = min(self.ncol - 1, col + 2)\n",
    "        elif action == 3:  # Up\n",
    "            row = max(0, row - 2)\n",
    "\n",
    "        new_state = row * self.ncol + col  # Calculate the new state\n",
    "\n",
    "        # Ensure the new state is valid (in range)\n",
    "        if 0 <= new_state < self.nrow * self.ncol:\n",
    "            return new_state\n",
    "        else:\n",
    "            return None  # If invalid, return None\n",
    "\n",
    "    def move_enemy(self):\n",
    "        \"\"\"\n",
    "        Moves the enemy towards the agent's position.\n",
    "        \"\"\"\n",
    "        if not self.enemy_active:\n",
    "            return\n",
    "\n",
    "        # Restore the original content of the enemy's current tile\n",
    "        original_tile = self.desc_original[self.enemy_pos[0]][self.enemy_pos[1]]\n",
    "        self.desc[self.enemy_pos[0]][self.enemy_pos[1]] = original_tile\n",
    "\n",
    "        agent_row, agent_col = self.agent_pos\n",
    "        enemy_row, enemy_col = self.enemy_pos\n",
    "\n",
    "        # Determine the direction of movement\n",
    "        if enemy_row < agent_row:\n",
    "            new_enemy_row = enemy_row + 1\n",
    "            new_enemy_col = enemy_col\n",
    "        elif enemy_row > agent_row:\n",
    "            new_enemy_row = enemy_row - 1\n",
    "            new_enemy_col = enemy_col\n",
    "        elif enemy_col < agent_col:\n",
    "            new_enemy_col = enemy_col + 1\n",
    "            new_enemy_row = enemy_row\n",
    "        elif enemy_col > agent_col:\n",
    "            new_enemy_col = enemy_col - 1\n",
    "            new_enemy_row = enemy_row\n",
    "        else:\n",
    "            new_enemy_row = enemy_row\n",
    "            new_enemy_col = enemy_col\n",
    "\n",
    "        # Determine the direction of movement\n",
    "        if self.boost_active:\n",
    "            if enemy_row < agent_row:\n",
    "                new_enemy_row = enemy_row + 2\n",
    "                new_enemy_col = enemy_col\n",
    "            elif enemy_row > agent_row:\n",
    "                new_enemy_row = enemy_row - 2\n",
    "                new_enemy_col = enemy_col\n",
    "            elif enemy_col < agent_col:\n",
    "                new_enemy_col = enemy_col + 2\n",
    "                new_enemy_row = enemy_row\n",
    "            elif enemy_col > agent_col:\n",
    "                new_enemy_col = enemy_col - 2\n",
    "                new_enemy_row = enemy_row\n",
    "            else:\n",
    "                new_enemy_row = enemy_row\n",
    "                new_enemy_col = enemy_col\n",
    "\n",
    "        # Ensure the new enemy position is within the bounds and not a hole -> enemy can jump over holes for easier implementation\n",
    "        if (0 <= new_enemy_row < self.nrow and 0 <= new_enemy_col < self.ncol and\n",
    "                self.desc[new_enemy_row][new_enemy_col] != self.hole_tile.encode()):\n",
    "            self.enemy_pos = (new_enemy_row, new_enemy_col)\n",
    "        # Update the map with the new enemy position\n",
    "        self.desc[self.enemy_pos[0]][self.enemy_pos[1]] = self.enemy_tile.encode()\n",
    "\n",
    "    def remove_enemy(self): # Remove Enemy once defeated\n",
    "        self.desc[self.enemy_pos[0]][self.enemy_pos[1]] = self.frozen_tile.encode()\n",
    "        self.enemy_pos = (-1, -1)\n",
    "        self.enemy_active = False\n",
    "    \n",
    "    def get_reward(self, row, col):\n",
    "        if self.desc[row][col] == self.goal_tile.encode():\n",
    "            return 20  # High reward for reaching the goal\n",
    "        elif self.desc[row][col] == self.hole_tile.encode():\n",
    "            return -20  # High penalty for falling into a hole\n",
    "        elif self.desc[row][col] == self.enemy_tile.encode() and not self.has_weapon:\n",
    "            return -20  # High penalty for colliding with the enemy\n",
    "        elif self.desc[row][col] == self.weapon_tile.encode():\n",
    "            return 10 # Reward for collecting weapon\n",
    "        elif self.desc[row][col] == self.enemy_tile.encode() and self.has_weapon:\n",
    "            return 15  # Higher reward for defeating the enemy\n",
    "        else:\n",
    "            return -1  # Small penalty for each step taken to motivate finding the shortest path\n",
    "        \n",
    "    def render(self, mode='ansi', action=None):\n",
    "        desc = self.desc.tolist()\n",
    "        if mode == 'ansi':\n",
    "            desc = [[c.decode('utf-8') for c in line] for line in desc]\n",
    "            output = StringIO()\n",
    "            if action is not None:\n",
    "                output.write(f\"Action taken: {ACTION_NAMES[action]}\\n\")\n",
    "            for i, row in enumerate(desc):\n",
    "                for j, cell in enumerate(row):\n",
    "                    if (i, j) == self.agent_pos:\n",
    "                        output.write('\\033[94m' + 'A' + '\\033[0m' + ' ')  # Highlight the agent position in blue\n",
    "                    elif (i, j) == self.enemy_pos:\n",
    "                        output.write('\\033[91m' + 'E' + '\\033[0m' + ' ')  # Highlight the enemy position in red\n",
    "                    else:\n",
    "                        output.write(cell + ' ')\n",
    "                output.write('\\n')\n",
    "            return output.getvalue()\n",
    "        else:\n",
    "            return super().render(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863d486",
   "metadata": {},
   "source": [
    "### Define Custom Map with Booster Tile"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b73710e3",
   "metadata": {},
   "source": [
    "# Example for State Description\n",
    "S F F F F B F H (S: starting point for agent, safe)\n",
    "B H H H F H F B (F: frozen surface, safe)\n",
    "H W F B F F F F (W: weapon, agent can defeat enemy with this) -> new\n",
    "B H F F H F F E (E: starting point for enemy, death) -> new\n",
    "F F H F F F H F (H: hole, stuck forever)\n",
    "F B F F H F F B (B: booster, safe) -> new \n",
    "F F F H F F H H\n",
    "F F F H F F H G (G: goal, safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b4577d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation states:  64\n",
      "Number of action space :  4\n"
     ]
    }
   ],
   "source": [
    "# ANSI rendering for JN doesn't seem to be working for custom environment so workaround for visualization is needed\n",
    "# Define action names for clarity in rendering\n",
    "ACTION_NAMES = [\"Left\", \"Down\", \"Right\", \"Up\"]\n",
    "\n",
    "# Example custom map with boosters B and enemy E\n",
    "custom_map = [\n",
    "    \"FFFFFBFH\", # Agents starts in top left corner # Booster allows to move 2 tiles at once and jump across holes\n",
    "    \"BHHHFHFB\", \n",
    "    \"HWFBFFFF\", # Weapon, agent will have to reach this tile before meeting enemy -> weapon has to be reachable before enemy gets too close\n",
    "    \"BHFFHFFF\", # Enemy starts here at the very right and is a dynamic antagonist chasing the agent -> if caught -> end of game\n",
    "    \"FFHFFFHF\",\n",
    "    \"FBFFHFFB\",\n",
    "    \"FFFHFFHH\",\n",
    "    \"FFFHFFHG\"  # Goal is surrounde by holes so agent *has* to find the booster to jump across\n",
    "]\n",
    "\n",
    "env_new = CustomFrozenLakeEnv(desc=custom_map, is_slippery=False)\n",
    "\n",
    "print(\"Number of observation states: \", env_new.observation_space.n)\n",
    "print(\"Number of action space : \", env_new.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b355145",
   "metadata": {},
   "source": [
    "### Define Action Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0fdea253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_new(state, epsilon):\n",
    "    \"\"\"\n",
    "    The choose_action() function uses an epsilon-greedy policy for exploration and exploitation.\n",
    "\n",
    "    Args:\n",
    "        state (int): Current state.\n",
    "        epsilon (float): Exploration rate.\n",
    "\n",
    "    Returns:\n",
    "        int: Action to be taken in that state.\n",
    "    \"\"\"\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return env_new.action_space.sample()  # Explore: choose a random action\n",
    "    else:\n",
    "        return np.argmax(Q_new[state, :])     # Exploit: choose the action with the highest value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665a351",
   "metadata": {},
   "source": [
    "### Define Learning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3d4ffcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_new(state, state2, reward, action):\n",
    "    \"\"\"\n",
    "    Updates the Q-table.\n",
    "\n",
    "    Args:\n",
    "        state (int): Current state\n",
    "        state2 (int): Future state\n",
    "        reward (int): Reward if reached the goal state\n",
    "        action (int): Action taken\n",
    "    \"\"\"\n",
    "    predict = Q_new[state, action]\n",
    "    target = reward + gamma * np.max(Q_new[state2, :])\n",
    "    Q_new[state, action] = Q_new[state, action] + lr_rate * (target - predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373fddbd",
   "metadata": {},
   "source": [
    "### Initialize New Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "232d56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Q-table\n",
    "Q_new = np.zeros((env_new.observation_space.n, env_new.action_space.n))\n",
    "Q_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ac6ff",
   "metadata": {},
   "source": [
    "### Look at a Try Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "189b60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mA\u001b[0m F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F F \u001b[91mE\u001b[0m \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Up\n",
      "\u001b[94mA\u001b[0m F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F \u001b[91mE\u001b[0m \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Up\n",
      "\u001b[94mA\u001b[0m F F F F B F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "\u001b[94mA\u001b[0m H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Up\n",
      "\u001b[94mA\u001b[0m F F F F B F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reset environment to initial state\n",
    "state, _ = env_new.reset()\n",
    "\n",
    "# Render the initial state\n",
    "print(env_new.render())\n",
    "\n",
    "# Take a few random steps to see the environment in action\n",
    "for _ in range(4):\n",
    "    action = env_new.action_space.sample()  # Choose a random action\n",
    "    state, reward, done, truncated, info = env_new.step(action)\n",
    "    print(env_new.render(action=action))\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32db10",
   "metadata": {},
   "source": [
    "### Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5bacc536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rewards_new = []\n",
    "epsilon = initial_epsilon\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    state, _ = env_new.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        action = choose_action_new(state, epsilon)\n",
    "        state2, reward, done, truncated, info = env_new.step(action)\n",
    "\n",
    "        learn_new(state, state2, reward, action)\n",
    "\n",
    "        total_reward += reward\n",
    "        state = state2\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "    rewards_new.append(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc18af8",
   "metadata": {},
   "source": [
    "### Plot Reward Function Over Iterations of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "297e8581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate average reward per 100 episodes\n",
    "avg_rewards_new = []\n",
    "for i in range(0, len(rewards), 100):\n",
    "    avg_rewards_new.append(np.mean(rewards[i:i + 100]))\n",
    "\n",
    "plt.plot(avg_rewards)\n",
    "plt.xlabel('Episode Number x100')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Total Average Reward per 100 Episodes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6455ed",
   "metadata": {},
   "source": [
    "### Look at a Walkthrough after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a57ed879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final try after training:\n",
      "Action taken: Right\n",
      "F \u001b[94mA\u001b[0m F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F \u001b[91mE\u001b[0m \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F \u001b[94mA\u001b[0m F F B F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F F \u001b[94mA\u001b[0m F B F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F F F \u001b[94mA\u001b[0m B F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F F F F \u001b[94mA\u001b[0m F H \n",
      "B H H H F H F \u001b[91mE\u001b[0m \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F \u001b[94mA\u001b[0m F \u001b[91mE\u001b[0m \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H \u001b[94mA\u001b[0m F \u001b[91mE\u001b[0m \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F \u001b[94mA\u001b[0m F \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Right\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F F \u001b[94mA\u001b[0m \n",
      "F F H F F F H F \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H \u001b[94mA\u001b[0m \n",
      "F B F F H F F B \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H \u001b[91mE\u001b[0m \n",
      "F B F F H F F \u001b[94mA\u001b[0m \n",
      "F F F H F F H H \n",
      "F F F H F F H G \n",
      "\n",
      "Action taken: Down\n",
      "F F F F F B F H \n",
      "B H H H F H F B \n",
      "H W F B F F F F \n",
      "B H F F H F F F \n",
      "F F H F F F H F \n",
      "F B F F H F F \u001b[91mE\u001b[0m \n",
      "F F F H F F H H \n",
      "F F F H F F H \u001b[94mA\u001b[0m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Render the environment after training is complete\n",
    "state, _ = env_new.reset()  # Reset the environment for the final render\n",
    "t = 0\n",
    "\n",
    "print(\"Final try after training:\")\n",
    "while t < max_steps:\n",
    "    action = np.argmax(Q_new[state, :])  # Take the best action based on the learned Q-table\n",
    "    state, reward, done, truncated, info = env_new.step(action)  # Take action and observe outcome\n",
    "    print(env_new.render(action=action))  # Render the environment after training\n",
    "    t += 1\n",
    "\n",
    "    if done:  # End episode if goal is reached\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40fa3",
   "metadata": {},
   "source": [
    "### Look at and Save Our Trained Q-Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1c4bc326",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.36618461,   5.30252276,   7.44059051,   6.36618461],\n",
       "       [  6.36618461, -20.        ,   8.525849  ,   7.44059051],\n",
       "       [  7.44059051, -20.        ,   9.6220697 ,   8.525849  ],\n",
       "       [  8.525849  , -20.        ,  10.72936333,   9.6220697 ],\n",
       "       [  9.6220697 ,  10.72936333,  11.84784175,  10.72936333],\n",
       "       [  9.6220697 ,  12.97761793, -20.        ,  11.84784175],\n",
       "       [ -3.17465096,  10.15396521, -19.278     , -21.3733688 ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  5.30252276,   4.24949753, -20.        ,   6.36618461],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-20.        ,  11.84784175, -20.        ,  10.72936333],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-19.9739358 ,  14.11880599,  11.78928351,  -2.79750602],\n",
       "       [-19.99905908,  16.43587996,   8.84899168, -19.278     ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-19.9739358 , -19.9950478 ,  -6.42554961, -19.9950478 ],\n",
       "       [ -5.95456794,  -7.68713199, -19.50097642, -19.278     ],\n",
       "       [ -6.77856179,  -3.93452421,  12.97761793,   7.03670236],\n",
       "       [ 11.84784175, -20.        ,  12.97761793,  10.72936333],\n",
       "       [ 11.84784175,  14.11880599,  14.11880599, -20.        ],\n",
       "       [ 12.97761793,  15.2715212 ,  15.2715212 ,  12.97761793],\n",
       "       [ 14.11880599,  16.43588   ,  -3.7284788 ,  15.27151581],\n",
       "       [  1.9770063 ,  -6.79195265,  -5.85879059,   5.30252276],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-20.        , -20.        ,  -4.90192324,  -6.8536694 ],\n",
       "       [ -4.56722472,  -3.93859095, -19.99999355,  -4.38350029],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-20.        ,  12.99335181,  15.2715212 ,  12.97761793],\n",
       "       [ 14.11880599, -20.        ,  16.43588   ,  14.11880599],\n",
       "       [ 15.2715212 ,  17.612     ,  -2.56412   ,  15.2715212 ],\n",
       "       [ -6.47148635,  -6.69017431,  -6.44855085,  -7.0297622 ],\n",
       "       [ -6.41650577,  -5.81228406, -19.9739358 , -19.9739358 ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-19.99999355,  -4.89797184,  11.67164717,  -4.87134313],\n",
       "       [  7.14614336, -19.99996603,  15.27095321, -19.9739358 ],\n",
       "       [ 14.10625756,  13.8670614 , -20.        ,  14.11880599],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-20.        ,  18.8       ,  -1.388     ,  16.43588   ],\n",
       "       [ -6.77730488,  -6.98891778,  -5.85058873,  -7.09562491],\n",
       "       [ -6.7825013 ,  -6.11187645,  -4.8996953 , -19.99982123],\n",
       "       [ -5.64999237,  -5.3413381 ,  -4.89698291, -19.278     ],\n",
       "       [ -5.7787997 , -19.9739358 , -19.99999996,   7.14548893],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-20.        ,  12.19567813,  14.6879    ,  12.98302819],\n",
       "       [ 16.43588   , -19.99999999,  18.8       , -19.99996603],\n",
       "       [ 12.01007137,  20.        ,  18.8       ,  16.43588   ],\n",
       "       [ -6.16434309,  -6.97641789,  -6.236518  ,  -6.06259327],\n",
       "       [ -6.23800004,  -5.75113609,  -5.81435259,  -5.84871132],\n",
       "       [ -4.90340596,  -5.6221033 , -19.86282   ,  -5.46704244],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-16.2       ,   0.        ,   0.        , -16.2       ],\n",
       "       [ -0.81      ,  -0.993141  , -16.2       ,  12.08549867],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ -6.37062722,  -6.46488939,  -6.10263   ,  -6.90095738],\n",
       "       [ -6.08371548,  -5.9333368 ,  -6.31096299,  -6.67213714],\n",
       "       [ -6.28927855,  -5.60032001, -19.99999977,  -5.50871644],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  -0.81      ,  -0.81      ],\n",
       "       [ -0.9639    ,   0.        , -16.2       ,  11.1627953 ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "853b0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the Q-table in pickle file for easy loading when needed.\n",
    "with open(\"frozenLake_new_qTable.pkl\", 'wb') as f:\n",
    "    pickle.dump(Q_new, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (rlcard)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
